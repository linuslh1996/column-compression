{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import seaborn as sns\n",
    "import load_workload_data as ld\n",
    "import load_benchmark_data as be\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 2160x1008 with 0 Axes>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "# Init\n",
    "sns.set()\n",
    "sns.set(rc={'figure.figsize':(30,14)})\n",
    "sns.set(font_scale=6.5)\n",
    "plt.tight_layout()\n",
    "workloads: Path = Path(\"../data/workloads/\")\n",
    "\n",
    "def plot_stacked(data: DataFrame, x: str, y: str, hue: str, hue_order: List[str]=None, order: List[str]=None, color=None):\n",
    "    df_plottable: DataFrame = data.groupby([x, hue])[y].sum().reset_index().pivot(columns=hue, index=x, values=y)\n",
    "    if hue_order:\n",
    "        assert sorted(hue_order) == sorted(list(df_plottable))\n",
    "        df_plottable = df_plottable[hue_order]\n",
    "    if order:\n",
    "        df_plottable = df_plottable.reindex(order)\n",
    "    df_plottable.plot(kind=\"bar\", stacked=True, ax=plt.gca(), rot=0)\n",
    "    plt.ylabel(y)\n",
    "\n",
    "def plot_workload(workload_folder: Path):\n",
    "    df = ld.get_workload_data(workload_folder)\n",
    "    x_order: List[str] = sorted(df[ld.DATA_TYPE].drop_duplicates(), reverse=True)\n",
    "    order: List[str] = [\"TABLE_SCAN\", \"JOIN\", \"AGGREGATE\", \"PROJECTION\"]\n",
    "    order_filtered = [operator for operator in order if operator in list(df[ld.OPERATOR_TYPE])]\n",
    "    plot_stacked(data=df, x=ld.DATA_TYPE, y=ld.RUNTIME_S, hue=ld.OPERATOR_TYPE, hue_order=order_filtered, order=x_order)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import sys\n",
    "from enum import Enum\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "class Operator(str, Enum):\n",
    "    SCAN = \"table_scans\",\n",
    "    PROJECTION = \"projections\",\n",
    "    AGGREGATE = \"aggregates\",\n",
    "    JOIN = \"joins\"\n",
    "\n",
    "RUNTIME_S = \"Runtime (in s)\"\n",
    "COLUMN_TYPE = \"Data Access\"\n",
    "QUERY_HASH = \"QUERY_HASH\"\n",
    "OPERATOR_HASH = \"OPERATOR_HASH\"\n",
    "DATA_TYPE = \"Data Type\"\n",
    "TABLE_NAME = \"TABLE_NAME\"\n",
    "COLUMN_NAME = \"COLUMN_NAME\"\n",
    "OPERATOR_TYPE = \"Operator\"\n",
    "WORKLOAD = \"WORKLOAD\"\n",
    "\n",
    "BENCHMARKS: List[str] = [\"CH-benCHmark\", \"Join Order Benchmark\", \"TPC-C\", \"TPC-DS\", \"TPC-H\"]\n",
    "\n",
    "def get_with_column_data_type(table: DataFrame, metadata: DataFrame) -> DataFrame:\n",
    "    table[TABLE_NAME] = table[TABLE_NAME].astype(object)\n",
    "    table[COLUMN_NAME] = table[COLUMN_NAME].astype(object)\n",
    "    table_with_data_types = table.merge(metadata, how=\"left\", on=[TABLE_NAME, COLUMN_NAME])\n",
    "    return table_with_data_types\n",
    "\n",
    "def get_grouped_by_operator_hash(table: DataFrame) -> DataFrame:\n",
    "    grouped_by_operator_hash: DataFrame = table.groupby([QUERY_HASH, OPERATOR_HASH], as_index=False)[RUNTIME_S] \\\n",
    "        .agg([\"count\", \"mean\"])\n",
    "    grouped_by_operator_hash[RUNTIME_S] = [mean / count for mean, count in zip(grouped_by_operator_hash[\"mean\"], grouped_by_operator_hash[\"count\"])]\n",
    "    grouped_by_operator_hash = grouped_by_operator_hash.reset_index()\n",
    "\n",
    "    table = table.drop(RUNTIME_S, axis=1)\n",
    "    table = table.merge(grouped_by_operator_hash, on=[QUERY_HASH, OPERATOR_HASH])\n",
    "    return table\n",
    "\n",
    "def get_workload_data(workload_directory: Path) -> DataFrame:\n",
    "    # Initialize\n",
    "    metadata = pd.read_csv(workload_directory / \"column_meta_data.csv\", delimiter=\"|\")\n",
    "    metadata = metadata.rename(columns={\"DATA_TYPE\": DATA_TYPE})\n",
    "    workload_name: str = workload_directory.name\n",
    "    aggregated_data = []\n",
    "    for operator in list(Operator):\n",
    "        # print(f\"Processing {operator}\")\n",
    "\n",
    "        # Get Dataframe\n",
    "        table: DataFrame = pd.read_csv(workload_directory / f\"{operator}.csv\", delimiter=\"|\")\n",
    "        #print(table)\n",
    "        table[\"RUNTIME_NS\"] = [runtime / 1e9 for runtime in table[\"RUNTIME_NS\"]]\n",
    "        table = table.rename(columns={\"RUNTIME_NS\" : RUNTIME_S, \"DATA_TYPE\": DATA_TYPE,\n",
    "                                      \"COLUMN_TYPE\": COLUMN_TYPE, \"OPERATOR_TYPE\": OPERATOR_TYPE})\n",
    "        table[WORKLOAD] = [workload_name for i in range(len(table))]\n",
    "\n",
    "        # Preprocess in case that we have a join (since both columns that we join on have the same type, we\n",
    "        # select the left column as the \"true\" column)\n",
    "        if operator is Operator.JOIN:\n",
    "            table = table.rename({f\"LEFT_COLUMN_NAME\": COLUMN_NAME, f\"LEFT_COLUMN_TYPE\":COLUMN_TYPE,\n",
    "                                 f\"LEFT_TABLE_NAME\":TABLE_NAME}, axis=\"columns\")\n",
    "\n",
    "        # Groupby to avoid having missleading results\n",
    "        if operator is not Operator.SCAN:\n",
    "            table = get_grouped_by_operator_hash(table)\n",
    "        table = get_with_column_data_type(table, metadata)\n",
    "\n",
    "        # Calculate Information\n",
    "        #grouped_by_column_type: DataFrame = table.groupby([COLUMN_TYPE, DATA_TYPE, OPERATOR_TYPE, WORKLOAD], as_index=False)[RUNTIME_S].sum().reset_index()\n",
    "        # 0: DATA, 1: REFERENCE\n",
    "        aggregated_data.append((str(operator), table.groupby(COLUMN_TYPE)[COLUMN_TYPE].count()[0], table.groupby(COLUMN_TYPE)[COLUMN_TYPE].count()[1]))\n",
    "    return aggregated_data\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TPC-H 14654 16564\n",
      "TPC-DS 44150 82227\n",
      "CH-benCHmark 45779 925270\n",
      "TPC-C 2264 40729\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-5b57d11159c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrelative\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"TPC-H\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TPC-DS\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"CH-benCHmark\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TPC-C\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Join Order Benchmark\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_workload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkloads\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-b9fc8c507d15>\u001b[0m in \u001b[0;36mget_workload_data\u001b[0;34m(workload_directory)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m#grouped_by_column_type: DataFrame = table.groupby([COLUMN_TYPE, DATA_TYPE, OPERATOR_TYPE, WORKLOAD], as_index=False)[RUNTIME_S].sum().reset_index()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m# 0: DATA, 1: REFERENCE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0maggregated_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCOLUMN_TYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCOLUMN_TYPE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCOLUMN_TYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCOLUMN_TYPE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0maggregated_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/develop/column-compression/venv/lib/python3.9/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_fallback_to_positional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "relative = []\n",
    "for b in [\"TPC-H\", \"TPC-DS\", \"CH-benCHmark\", \"TPC-C\", \"Join Order Benchmark\"]:\n",
    "    d = get_workload_data(workloads / b)\n",
    "    data = sum([v[1] for v in d])\n",
    "    ref = sum([v[2] for v in d])\n",
    "    print(b, data, ref)\n",
    "    relative.append(data / (data + ref))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.770359046216605"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "sum([1-r for r in relative]) / 4"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.3116443658189082"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "relative = []\n",
    "for b in [\"TPC-H\", \"TPC-DS\", \"CH-benCHmark\", \"TPC-C\", \"Join Order Benchmark\"]:\n",
    "    table: DataFrame = pd.read_csv(workloads / b / f\"table_scans.csv\", delimiter=\"|\")\n",
    "    #print(table)\n",
    "    table[\"selectivity\"] = table[\"OUTPUT_ROW_COUNT\"] / table[\"INPUT_ROW_COUNT\"]\n",
    "    #break\n",
    "    relative.append(table[\"selectivity\"].mean())\n",
    "sum(relative) / len(relative)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.4073986681907011,\n",
       " 0.23868022680140927,\n",
       " 0.10919891562679623,\n",
       " 0.1727336854886215,\n",
       " 0.6302103329870131]"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.9.1-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}